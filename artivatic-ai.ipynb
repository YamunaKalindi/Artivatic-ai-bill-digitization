{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceType":"datasetVersion","sourceId":2230405,"datasetId":1339864,"databundleVersionId":2272174},{"sourceType":"datasetVersion","sourceId":14891880,"datasetId":9528239,"databundleVersionId":15755807},{"sourceType":"datasetVersion","sourceId":14899028,"datasetId":9532994,"databundleVersionId":15763603}],"dockerImageVersionId":31287,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install transformers datasets seqeval","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-20T17:22:19.647383Z","iopub.execute_input":"2026-02-20T17:22:19.647658Z","iopub.status.idle":"2026-02-20T17:22:27.142821Z","shell.execute_reply.started":"2026-02-20T17:22:19.647633Z","shell.execute_reply":"2026-02-20T17:22:27.142173Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (5.2.0)\nRequirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\nCollecting seqeval\n  Downloading seqeval-1.2.2.tar.gz (43 kB)\n\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: huggingface-hub<2.0,>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (1.4.1)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.11.3)\nRequirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.2)\nRequirement already satisfied: typer-slim in /usr/local/lib/python3.12/dist-packages (from transformers) (0.21.1)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.7.0)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets) (3.20.3)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (18.1.0)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.3.3)\nRequirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.32.4)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\nRequirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\nRequirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.12/dist-packages (from seqeval) (1.6.1)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.13.3)\nRequirement already satisfied: hf-xet<2.0.0,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=1.3.0->transformers) (1.2.0)\nRequirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=1.3.0->transformers) (0.28.1)\nRequirement already satisfied: shellingham in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=1.3.0->transformers) (1.5.4)\nRequirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=1.3.0->transformers) (4.15.0)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (3.4.4)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (3.11)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (2026.1.4)\nRequirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.16.3)\nRequirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.5.3)\nRequirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.6.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.3)\nRequirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer-slim->transformers) (8.3.1)\nRequirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\nRequirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.4.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.8.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.7.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.4.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.22.0)\nRequirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers) (4.12.1)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers) (1.0.9)\nRequirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers) (0.16.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\nBuilding wheels for collected packages: seqeval\n  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16162 sha256=de81ce2f4ca4ade2ac67acf50f23c929183b13ec9849bf9dc0d900304c465399\n  Stored in directory: /root/.cache/pip/wheels/5f/b8/73/0b2c1a76b701a677653dd79ece07cfabd7457989dbfbdcd8d7\nSuccessfully built seqeval\nInstalling collected packages: seqeval\nSuccessfully installed seqeval-1.2.2\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import json\nfrom PIL import Image\nimport os\n\ndef load_funsd_split(split=\"training\"):\n    data = []\n    \n    base = \"/kaggle/input/datasets/aravindram11/funsdform-understanding-noisy-scanned-documents/dataset\"\n    \n    ann_dir = f\"{base}/{split}_data/annotations\"\n    img_dir = f\"{base}/{split}_data/images\"\n    \n    for file in os.listdir(ann_dir):\n        if not file.endswith(\".json\"):\n            continue\n        \n        with open(os.path.join(ann_dir, file), \"r\") as f:\n            ann = json.load(f)\n        \n        image_path = os.path.join(img_dir, file.replace(\".json\", \".png\"))\n        image = Image.open(image_path).convert(\"RGB\")\n        \n        tokens = []\n        bboxes = []\n        ner_tags = []\n        \n        for item in ann[\"form\"]:\n            label = item[\"label\"].upper()\n            words = item[\"words\"]\n            \n            for idx, word in enumerate(words):\n                tokens.append(word[\"text\"])\n                bboxes.append(word[\"box\"])\n                \n                if label == \"OTHER\":\n                    ner_tags.append(\"O\")\n                else:\n                    prefix = \"B-\" if idx == 0 else \"I-\"\n                    ner_tags.append(prefix + label)\n        \n        data.append({\n            \"id\": file,\n            \"tokens\": tokens,\n            \"bboxes\": bboxes,\n            \"ner_tags\": ner_tags,\n            \"image\": image\n        })\n    \n    return data","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-20T18:27:16.749279Z","iopub.execute_input":"2026-02-20T18:27:16.749879Z","iopub.status.idle":"2026-02-20T18:27:16.756739Z","shell.execute_reply.started":"2026-02-20T18:27:16.749851Z","shell.execute_reply":"2026-02-20T18:27:16.755996Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"train_data = load_funsd_split(\"training\")\ntest_data = load_funsd_split(\"testing\")\n\nprint(\"Train size:\", len(train_data))\nprint(\"Test size:\", len(test_data))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-20T18:27:20.922953Z","iopub.execute_input":"2026-02-20T18:27:20.923684Z","iopub.status.idle":"2026-02-20T18:27:23.067828Z","shell.execute_reply.started":"2026-02-20T18:27:20.923655Z","shell.execute_reply":"2026-02-20T18:27:23.067055Z"}},"outputs":[{"name":"stdout","text":"Train size: 149\nTest size: 50\n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"label_list = list(set(tag for doc in train_data for tag in doc[\"ner_tags\"]))\nlabel_list = sorted(label_list)\n\nlabel2id = {label: i for i, label in enumerate(label_list)}\nid2label = {i: label for label, i in label2id.items()}\n\nprint(label_list)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-20T18:28:29.643031Z","iopub.execute_input":"2026-02-20T18:28:29.643329Z","iopub.status.idle":"2026-02-20T18:28:29.650609Z","shell.execute_reply.started":"2026-02-20T18:28:29.643303Z","shell.execute_reply":"2026-02-20T18:28:29.649719Z"}},"outputs":[{"name":"stdout","text":"['B-ANSWER', 'B-HEADER', 'B-QUESTION', 'I-ANSWER', 'I-HEADER', 'I-QUESTION', 'O']\n","output_type":"stream"}],"execution_count":31},{"cell_type":"code","source":"from transformers import LayoutLMv3Processor, LayoutLMv3ForTokenClassification\n\nfrom transformers import LayoutLMv3ImageProcessor, LayoutLMv3TokenizerFast, LayoutLMv3Processor\n\nimage_processor = LayoutLMv3ImageProcessor.from_pretrained(\n    \"microsoft/layoutlmv3-base\",\n    apply_ocr=False  # üî• VERY IMPORTANT\n)\n\ntokenizer = LayoutLMv3TokenizerFast.from_pretrained(\"microsoft/layoutlmv3-base\")\n\nprocessor = LayoutLMv3Processor(image_processor, tokenizer)\n\nmodel = LayoutLMv3ForTokenClassification.from_pretrained(\n    \"microsoft/layoutlmv3-base\",\n    num_labels=len(label_list),\n    id2label=id2label,\n    label2id=label2id\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-20T18:28:32.460471Z","iopub.execute_input":"2026-02-20T18:28:32.460789Z","iopub.status.idle":"2026-02-20T18:28:33.752843Z","shell.execute_reply.started":"2026-02-20T18:28:32.460740Z","shell.execute_reply":"2026-02-20T18:28:33.743935Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading weights:   0%|          | 0/212 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6605a706363c4b77a33e38e95c33cc47"}},"metadata":{}},{"name":"stderr","text":"\u001b[1mLayoutLMv3ForTokenClassification LOAD REPORT\u001b[0m from: microsoft/layoutlmv3-base\nKey                                | Status     | \n-----------------------------------+------------+-\nlayoutlmv3.embeddings.position_ids | UNEXPECTED | \nclassifier.weight                  | MISSING    | \nclassifier.bias                    | MISSING    | \n\n\u001b[3mNotes:\n- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n- MISSING\u001b[3m\t:those params were newly initialized because missing from the checkpoint. Consider training on your downstream task.\u001b[0m\n","output_type":"stream"}],"execution_count":32},{"cell_type":"code","source":"from datasets import Dataset\n\ntrain_dataset = Dataset.from_list(train_data)\ntest_dataset = Dataset.from_list(test_data)\n\ndef encode(example):\n    encoding = processor(\n        example[\"image\"],\n        example[\"tokens\"],\n        boxes=example[\"bboxes\"],\n        word_labels=[label2id[label] for label in example[\"ner_tags\"]],\n        truncation=True,\n        padding=\"max_length\",\n        return_tensors=\"pt\"\n    )\n\n    # üî• Remove batch dimension from each tensor\n    encoding = {k: v.squeeze(0) for k, v in encoding.items()}\n\n    return encoding\n\ntrain_dataset = train_dataset.map(encode, batched=False)\ntest_dataset = test_dataset.map(encode, batched=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-20T18:28:41.267635Z","iopub.execute_input":"2026-02-20T18:28:41.267956Z","iopub.status.idle":"2026-02-20T18:29:12.589621Z","shell.execute_reply.started":"2026-02-20T18:28:41.267930Z","shell.execute_reply":"2026-02-20T18:29:12.588863Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/149 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8985bef0ae114245a71979edd9b23795"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/50 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fbab48ac7f4b493db1e65a9a581e28f8"}},"metadata":{}}],"execution_count":33},{"cell_type":"code","source":"import transformers\nprint(transformers.__version__)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-20T17:37:08.225036Z","iopub.execute_input":"2026-02-20T17:37:08.225740Z","iopub.status.idle":"2026-02-20T17:37:08.229574Z","shell.execute_reply.started":"2026-02-20T17:37:08.225711Z","shell.execute_reply":"2026-02-20T17:37:08.228924Z"}},"outputs":[{"name":"stdout","text":"5.2.0\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"from seqeval.metrics import classification_report, f1_score\n\ndef compute_metrics(p):\n    predictions, labels = p\n    predictions = predictions.argmax(axis=2)\n\n    true_predictions = [\n        [id2label[p] for (p, l) in zip(pred, lab) if l != -100]\n        for pred, lab in zip(predictions, labels)\n    ]\n    true_labels = [\n        [id2label[l] for (p, l) in zip(pred, lab) if l != -100]\n        for pred, lab in zip(predictions, labels)\n    ]\n\n    return {\n        \"f1\": f1_score(true_labels, true_predictions)\n    }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-20T18:30:48.976168Z","iopub.execute_input":"2026-02-20T18:30:48.977139Z","iopub.status.idle":"2026-02-20T18:30:48.983327Z","shell.execute_reply.started":"2026-02-20T18:30:48.977104Z","shell.execute_reply":"2026-02-20T18:30:48.982550Z"}},"outputs":[],"execution_count":35},{"cell_type":"code","source":"from transformers import TrainingArguments, Trainer\n\ntraining_args = TrainingArguments(\n    output_dir=\"./layoutlmv3-funsd\",\n    per_device_train_batch_size=2,\n    per_device_eval_batch_size=2,\n    num_train_epochs=10,\n    eval_strategy=\"epoch\",\n    save_strategy=\"no\",\n    logging_steps=10,\n    learning_rate=3e-5,\n    weight_decay=0.01,\n    warmup_ratio=0.1,\n    max_grad_norm=1.0\n)\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,\n    eval_dataset=test_dataset,\n    compute_metrics=compute_metrics\n)\n\ntrainer.train()\nmetrics = trainer.evaluate()\nprint(metrics)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-20T18:31:23.875006Z","iopub.execute_input":"2026-02-20T18:31:23.875294Z","iopub.status.idle":"2026-02-20T18:38:09.316456Z","shell.execute_reply.started":"2026-02-20T18:31:23.875269Z","shell.execute_reply":"2026-02-20T18:38:09.315649Z"}},"outputs":[{"name":"stderr","text":"warmup_ratio is deprecated and will be removed in v5.2. Use `warmup_steps` instead.\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='380' max='380' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [380/380 06:36, Epoch 10/10]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.987033</td>\n      <td>1.619372</td>\n      <td>0.634624</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1.349043</td>\n      <td>1.331499</td>\n      <td>0.720055</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.987176</td>\n      <td>1.205467</td>\n      <td>0.757371</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.840203</td>\n      <td>1.215250</td>\n      <td>0.782911</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.480419</td>\n      <td>1.313016</td>\n      <td>0.785679</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>0.620000</td>\n      <td>1.376371</td>\n      <td>0.793069</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>0.358026</td>\n      <td>1.344589</td>\n      <td>0.793635</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>0.238793</td>\n      <td>1.388594</td>\n      <td>0.805963</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>0.218715</td>\n      <td>1.464901</td>\n      <td>0.809852</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>0.167741</td>\n      <td>1.457022</td>\n      <td>0.807130</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [13/13 00:06]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"{'eval_loss': 1.4570218324661255, 'eval_f1': 0.8071304778410497, 'eval_runtime': 6.9857, 'eval_samples_per_second': 7.157, 'eval_steps_per_second': 1.861, 'epoch': 10.0}\n","output_type":"stream"}],"execution_count":37},{"cell_type":"code","source":"!pip install seqeval","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-20T17:50:30.519688Z","iopub.execute_input":"2026-02-20T17:50:30.520538Z","iopub.status.idle":"2026-02-20T17:50:33.831516Z","shell.execute_reply.started":"2026-02-20T17:50:30.520494Z","shell.execute_reply":"2026-02-20T17:50:33.830820Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: seqeval in /usr/local/lib/python3.12/dist-packages (1.2.2)\nRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.12/dist-packages (from seqeval) (2.0.2)\nRequirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.12/dist-packages (from seqeval) (1.6.1)\nRequirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.16.3)\nRequirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.5.3)\nRequirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.6.0)\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"import torch\nimport numpy as np\n\ndef extract_structured_json(example):\n    model.eval()\n    \n    # Encode single example\n    encoding = processor(\n        example[\"image\"],\n        example[\"tokens\"],\n        boxes=example[\"bboxes\"],\n        truncation=True,\n        padding=\"max_length\",\n        return_tensors=\"pt\"\n    )\n\n    # Move to GPU if available\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    model.to(device)\n    encoding = {k: v.to(device) for k, v in encoding.items()}\n\n    with torch.no_grad():\n        outputs = model(**encoding)\n\n    logits = outputs.logits\n    predictions = torch.argmax(logits, dim=2).cpu().numpy()[0]\n\n    tokens = example[\"tokens\"]\n\n    structured_output = {}\n\n    current_entity = None\n    current_tokens = []\n\n    for token, pred_id in zip(tokens, predictions[:len(tokens)]):\n        label = id2label[pred_id]\n\n        if label == \"O\":\n            if current_entity:\n                text = \" \".join(current_tokens)\n                structured_output.setdefault(current_entity, []).append(text)\n                current_entity = None\n                current_tokens = []\n            continue\n\n        if label.startswith(\"B-\"):\n            if current_entity:\n                text = \" \".join(current_tokens)\n                structured_output.setdefault(current_entity, []).append(text)\n\n            current_entity = label[2:]\n            current_tokens = [token]\n\n        elif label.startswith(\"I-\") and current_entity == label[2:]:\n            current_tokens.append(token)\n\n        else:\n            if current_entity:\n                text = \" \".join(current_tokens)\n                structured_output.setdefault(current_entity, []).append(text)\n            current_entity = None\n            current_tokens = []\n\n    # Catch last entity\n    if current_entity and current_tokens:\n        text = \" \".join(current_tokens)\n        structured_output.setdefault(current_entity, []).append(text)\n\n    return {\n        \"document_id\": example[\"id\"],\n        \"extracted_fields\": structured_output\n    }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-20T18:57:30.068671Z","iopub.execute_input":"2026-02-20T18:57:30.069268Z","iopub.status.idle":"2026-02-20T18:57:30.078234Z","shell.execute_reply.started":"2026-02-20T18:57:30.069238Z","shell.execute_reply":"2026-02-20T18:57:30.077493Z"}},"outputs":[],"execution_count":39},{"cell_type":"code","source":"sample = test_data[0]\n\noutput_json = extract_structured_json(sample)\n\nimport json\nprint(json.dumps(output_json, indent=2))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-20T18:57:50.672350Z","iopub.execute_input":"2026-02-20T18:57:50.672895Z","iopub.status.idle":"2026-02-20T18:57:50.795931Z","shell.execute_reply.started":"2026-02-20T18:57:50.672854Z","shell.execute_reply":"2026-02-20T18:57:50.795039Z"}},"outputs":[{"name":"stdout","text":"{\n  \"document_id\": \"83823750.json\",\n  \"extracted_fields\": {\n    \"QUESTION\": [\n      \"To\",\n      \"2\",\n      \"Sender\",\n      \"Reference\",\n      \"Message:\",\n      \"83823750\",\n      \"Confidentiality Note:\",\n      \"212\",\n      \"-450 -5578\",\n      \"17560 -188\",\n      \"and may contain information that is privileged, confidential or\",\n      \"disclosure  distribution or\",\n      \"copying of this facsimile or the\",\n      \"the intended recipient, or an\"\n    ],\n    \"ANSWER\": [\n      \"Company\",\n      \"Charles Duggan Sender Voice Number Main Fax Operator\",\n      \"Voice Number 212 -450-\",\n      \"4785 Sender Fax Number\",\n      \"This facsimile  intended only  the person\",\n      \"or entity to which it is addressed\",\n      \"otherwise protected from\",\n      \"information herein by anyone other than\",\n      \"employee or agent responsible for delivering\",\n      \"the message to the\"\n    ],\n    \"HEADER\": [\n      \"Robert H. Shaw, Esq. November 11, 1997 Lorillard Tobacco\"\n    ]\n  }\n}\n","output_type":"stream"}],"execution_count":40}]}